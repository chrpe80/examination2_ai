{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlopen\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.tools.edenai import EdenAiTextToSpeechTool\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import cProfile\n",
    "from pympler import asizeof"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.277107600Z",
     "start_time": "2024-02-15T14:18:21.309702600Z"
    }
   },
   "id": "3d6c442676f772a0",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.289009700Z",
     "start_time": "2024-02-15T14:18:23.276107800Z"
    }
   },
   "id": "fb8706619281385b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# url = \"https://www.fass.se/LIF/product?userType=2&nplId=20141129000039\"\n",
    "# url = \"https://www.apoteket.se/halsotjanster/\"\n",
    "url = \"https://www.aftonbladet.se/nyheter/a/Rr77qd/aftonbladet-direkt?pinnedEntry=1215281\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.291007700Z",
     "start_time": "2024-02-15T14:18:23.285134Z"
    }
   },
   "id": "df985d8619b78f80",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_cost(nr_input_tokens: int, nr_output_tokens: int):\n",
    "    \"\"\"A utility function to check the price of a request\"\"\"\n",
    "    \n",
    "    price_one_input_token = 0.0005/1000\n",
    "    price_one_output_token = 0.0015/1000\n",
    "    price_input_tokens = nr_input_tokens * price_one_input_token\n",
    "    price_output_tokens = nr_output_tokens * price_one_output_token\n",
    "    total_price_us_dollars = price_input_tokens + price_output_tokens \n",
    "    total_price_kr = total_price_us_dollars * 10.48\n",
    "    \n",
    "    return f\"{round(total_price_kr, 2)}kr\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.301431100Z",
     "start_time": "2024-02-15T14:18:23.290009200Z"
    }
   },
   "id": "7a25ec1d77ed6c9e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get_cost(12289, 4096)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.338287900Z",
     "start_time": "2024-02-15T14:18:23.298917Z"
    }
   },
   "id": "314d1c760c4435fc",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TextToSpeach:\n",
    "    __slots__ = (\"url\", \"model\", \"plain_text\", \"summary\")\n",
    "    def __init__(self, url: str):\n",
    "        \"\"\"The constructor takes an url, checks if it's valid, if so, and if status code is 200, it sets self.url to url. Otherwise, it raises an exception\"\"\"\n",
    "        \n",
    "        status_code = self.check_url(url)\n",
    "        if status_code == 200:\n",
    "            self.url = url\n",
    "        elif status_code == 404:\n",
    "            raise ValueError(f\"The status code was {status_code}, which indicates that while the server itself is reachable, the specific page is not.\")\n",
    "        else:\n",
    "            raise ValueError(f\"The status code was {status_code}.\")\n",
    "\n",
    "        self.model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "        self.plain_text = None\n",
    "        self.summary = None\n",
    "\n",
    "    @staticmethod\n",
    "    def check_url(url: str):\n",
    "        \"\"\"Checks the status code of the given url when a request is sent\"\"\"\n",
    "        try:\n",
    "            connection = urlopen(url)\n",
    "            status_code = connection.getcode()\n",
    "            return status_code\n",
    "        except HTTPError:\n",
    "            return 404\n",
    "        \n",
    "    @staticmethod\n",
    "    def count_tokens(text: str) -> int:\n",
    "        max_nr_of_tokens_for_model_io_combined = 16385\n",
    "        max_output = 4096\n",
    "        \n",
    "        encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        nr_of_tokens = len(encoder.encode(text))\n",
    "        \n",
    "        difference = max_nr_of_tokens_for_model_io_combined - max_output\n",
    "        \n",
    "        if nr_of_tokens <= difference:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def set_text_content(self):\n",
    "        \"\"\"Collects the plain text from a website\"\"\"\n",
    "        \n",
    "        # Create an instance of WebBaseLoader and load the html\n",
    "        loader = WebBaseLoader(self.url)\n",
    "        data = loader.load()\n",
    "\n",
    "        # Create an instance of Html2TextTransformer, transform the html to plain text and extract the plain text\n",
    "        transformer = Html2TextTransformer()\n",
    "        docs_transformed = transformer.transform_documents(data)\n",
    "        plain_text = docs_transformed[0].page_content\n",
    "        \n",
    "        # If nr of tokens is more than max nr of tokens - max nr of output tokens, then the text will be split\n",
    "        if self.count_tokens(plain_text):\n",
    "            self.plain_text = plain_text\n",
    "        else:\n",
    "            text_splitter = TokenTextSplitter(chunk_size=5000, chunk_overlap=10)\n",
    "            texts = text_splitter.split_text(plain_text)\n",
    "            self.plain_text = texts\n",
    "\n",
    "    def set_text_summary(self):\n",
    "        \"\"\"Summarizes the text and sets self.summary\"\"\"\n",
    "\n",
    "        # System and user messages\n",
    "        system_message = \"You are a very powerful assistant\"\n",
    "        human_message = \"Summarize the text between backticks\\n```{}````\\nThe summary is max 100 words\"\n",
    "\n",
    "        # This variable will contain parts of the original text if the original text had to be split\n",
    "        summaries = []\n",
    "\n",
    "        # If self.plain_text is a list\n",
    "        if type(self.plain_text) == list:\n",
    "            # Iterate through the list and get a summary for each text and append to summaries\n",
    "            for text in self.plain_text:\n",
    "                messages = [SystemMessage(content=system_message), HumanMessage(content=human_message.format(text))]\n",
    "                response = self.model.invoke(messages)\n",
    "                summaries.append(response.content)\n",
    "\n",
    "            # Join the texts in a string and (if nr of tokens is acceptable) get a new summary on the whole, now much shorter text\n",
    "            summaries_str = \": \".join(summaries)\n",
    "\n",
    "            if self.count_tokens(summaries_str):\n",
    "                messages = [SystemMessage(content=system_message), HumanMessage(content=human_message.format(summaries_str))]\n",
    "                summary = self.model.invoke(messages)\n",
    "                self.summary = summary.content\n",
    "            else:\n",
    "                raise ValueError(f\"For now, this program cannot handle that many tokens. Read about the gpt-3.5-turbo-0125 for info\")\n",
    "\n",
    "        # if self.plain_text is a string\n",
    "        else:\n",
    "            messages = [SystemMessage(content=system_message), HumanMessage(content=human_message.format(self.plain_text))]\n",
    "            summary = self.model.invoke(messages)\n",
    "            self.summary = summary.content\n",
    "            \n",
    "        return self.summary\n",
    "\n",
    "    @staticmethod\n",
    "    def play(url: str):\n",
    "        \"\"\"Autoplay to be implemented\"\"\"\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the program\"\"\"\n",
    "        \n",
    "        # Run key methods\n",
    "        self.set_text_content()\n",
    "        self.set_text_summary()\n",
    "\n",
    "        # Create messages\n",
    "        system_message = (\"system\", f\"You are a very powerful assistant\")\n",
    "        user_message = (\"user\", \"Turn this text into speach: {text}\")\n",
    "\n",
    "        # Create an instance of EdenAiTextToSpeachTool (the tool that the agent will use)\n",
    "        tts = EdenAiTextToSpeechTool(providers=[\"amazon\"], language=\"en\", voice=\"MALE\", edenai_api_key=os.getenv(\"EDENAI_API_KEY\"))\n",
    "        tools = [tts]\n",
    "        \n",
    "        # Create the prompt\n",
    "        prompt = ChatPromptTemplate.from_messages([system_message, user_message, MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "        \n",
    "        # Create the agent\n",
    "        agent = create_openai_functions_agent(llm=self.model, tools=tools, prompt=prompt)\n",
    "        \n",
    "        # Create an agent executor\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "        # Run the agent with the summary\n",
    "        result = agent_executor.invoke({\"text\": self.summary})\n",
    "        \n",
    "        # Get the url where the soundfile is automatically downloaded\n",
    "        pattern = r\"(https.+)\"\n",
    "        result = re.search(pattern, result[\"output\"])\n",
    "        \n",
    "        url = result.group(0).replace(\")\", \"\")\n",
    "        \n",
    "        response = requests.get(url).content\n",
    "        \n",
    "        with open(f\"sound_files/output.mp3\", mode=\"wb\") as file:\n",
    "            file.write(response)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.339287800Z",
     "start_time": "2024-02-15T14:18:23.309432800Z"
    }
   },
   "id": "cfffd2c043bad7ec",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     instance = TextToSpeach(url)\n",
    "#     instance.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.340290Z",
     "start_time": "2024-02-15T14:18:23.314633600Z"
    }
   },
   "id": "94b91d3993e660c2",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     instance = TextToSpeach(url)\n",
    "#     initial_size = asizeof.asizeof(instance)\n",
    "#     instance.run()\n",
    "#     final_size = asizeof.asizeof(instance)\n",
    "#     return initial_size, final_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.341298400Z",
     "start_time": "2024-02-15T14:18:23.319612300Z"
    }
   },
   "id": "d273d00aae225c48",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     cProfile.run('main()')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.341298400Z",
     "start_time": "2024-02-15T14:18:23.323409700Z"
    }
   },
   "id": "6055571807f42654",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     initial, final = main()\n",
    "#     print(f\"Initial memory usage in bytes is: {initial} bytes\\nFinal memory usage in bytes is: {final} bytes\")\n",
    "#     print(f\"The additional usage when the program finished running is: {final - initial} bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.342296300Z",
     "start_time": "2024-02-15T14:18:23.326923900Z"
    }
   },
   "id": "fa1e0ed92f84cc34",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "instance = TextToSpeach(url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:23.593065200Z",
     "start_time": "2024-02-15T14:18:23.331285700Z"
    }
   },
   "id": "91ad77a0c12d4a99",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    instance.run()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:43.969255200Z",
     "start_time": "2024-02-15T14:18:23.594066100Z"
    }
   },
   "id": "91edfb6e418d611e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T14:18:43.979838200Z",
     "start_time": "2024-02-15T14:18:43.975802Z"
    }
   },
   "id": "f50616effd28f3b5",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
